<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Iris - Siri that actually does what you tell it to do:</title>
    <!-- Markdown rendering library -->
    <script src="https://cdn.jsdelivr.net/npm/marked@9.1.6/marked.min.js"></script>
    <style>
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto',
          sans-serif;
        margin: 0;
        padding: 0;
        background: #f5f5f7;
        min-height: 100vh;
        overflow-x: hidden;
        scroll-behavior: smooth;
      }

      /* Integration Button - Top Right */
      .integration-btn {
        position: absolute;
        top: 20px;
        right: 20px;
        background: rgba(255, 255, 255, 0.9);
        border: 1px solid #e0e0e0;
        border-radius: 20px;
        padding: 10px 20px;
        font-size: 14px;
        color: #333;
        cursor: pointer;
        transition: all 0.3s ease;
        backdrop-filter: blur(10px);
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
      }

      .integration-btn:hover {
        background: rgba(255, 255, 255, 1);
        transform: translateY(-2px);
        box-shadow: 0 6px 25px rgba(0, 0, 0, 0.15);
      }

      /* Main Container */
      .main-content {
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        min-height: 100vh;
        text-align: center;
        padding: 20px;
        transition: all 0.8s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      }

      .main-content.listening {
        justify-content: flex-start;
        padding-top: 12vh;
      }

      .main-content.responding {
        justify-content: flex-start;
        padding-top: 8%vh;
      }

      /* Welcome Text */
      .welcome-title {
        font-size: 3.5em;
        font-weight: 700;
        color: #1d1d1f;
        margin-bottom: 20px;
        letter-spacing: -0.02em;
        opacity: 1;
        transform: translateY(0);
        transition: all 0.6s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      }

      .welcome-title.hidden {
        display: none;
      }

      .welcome-subtitle {
        font-size: 1.5em;
        color: #6e6e73;
        margin-bottom: 80px;
        font-weight: 400;
        opacity: 1;
        transform: translateY(0);
        transition: all 0.6s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      }

      .welcome-subtitle.hidden {
        display: none;
      }

      /* Siri-like Animated Circle */
      .siri-container {
        position: relative;
        margin: 40px 0;
        transition: all 0.8s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      }

      .siri-container.enlarged {
        margin: 60px 0;
      }

      .siri-circle {
        width: 200px;
        height: 200px;
        border-radius: 50%;
        background: linear-gradient(45deg, #007aff, #5856d6, #af52de, #ff2d92);
        background-size: 300% 300%;
        animation: gradientShift 3s ease-in-out infinite,
          pulse 2s ease-in-out infinite;
        cursor: pointer;
        transition: all 0.8s cubic-bezier(0.25, 0.46, 0.45, 0.94);
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 10px 40px rgba(0, 122, 255, 0.3);
        position: relative;
      }

      .siri-circle:hover {
        transform: scale(1.05);
        box-shadow: 0 15px 50px rgba(0, 122, 255, 0.4);
      }

      .siri-circle.enlarged {
        width: 280px;
        height: 280px;
        transform: scale(1);
      }

      .siri-circle.enlarged:hover {
        transform: scale(1.02);
      }

      /* Special hover state when responding - indicates user can click for new request */
      .main-content.responding .siri-circle:hover {
        transform: scale(1.08);
        box-shadow: 0 20px 60px rgba(0, 122, 255, 0.6);
        filter: brightness(1.1);
        cursor: pointer;
        animation: gradientShift 0.8s ease-in-out infinite,
          pulseActive 1s ease-in-out infinite;
      }

      .main-content.responding .siri-circle:hover .siri-inner {
        background: rgba(255, 255, 255, 0.3);
      }

      /* Add a subtle hint animation when in responding state */
      .main-content.responding .siri-circle {
        animation: gradientShift 3s ease-in-out infinite,
          subtlePulse 3s ease-in-out infinite;
      }

      @keyframes subtlePulse {
        0%,
        70%,
        100% {
          transform: scale(1);
        }
        85% {
          transform: scale(1.02);
        }
      }

      .siri-circle.listening {
        animation: gradientShift 0.5s ease-in-out infinite,
          pulseActive 0.8s ease-in-out infinite,
          listeningGlow 1.5s ease-in-out infinite;
        box-shadow: 0 15px 60px rgba(0, 122, 255, 0.5);
      }

      .siri-circle.listening::before {
        content: '';
        position: absolute;
        top: -20px;
        left: -20px;
        right: -20px;
        bottom: -20px;
        border-radius: 50%;
        background: linear-gradient(45deg, #007aff, #5856d6, #af52de, #ff2d92);
        background-size: 300% 300%;
        animation: gradientShift 1s ease-in-out infinite,
          expandingRing 2s ease-in-out infinite;
        opacity: 0.3;
        z-index: -1;
      }

      .siri-circle.listening::after {
        content: '';
        position: absolute;
        top: -40px;
        left: -40px;
        right: -40px;
        bottom: -40px;
        border-radius: 50%;
        background: linear-gradient(45deg, #007aff, #5856d6, #af52de, #ff2d92);
        background-size: 300% 300%;
        animation: gradientShift 1.2s ease-in-out infinite,
          expandingRing 2.5s ease-in-out infinite;
        opacity: 0.2;
        z-index: -2;
      }

      .siri-inner {
        width: 120px;
        height: 120px;
        background: rgba(255, 255, 255, 0.2);
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        backdrop-filter: blur(10px);
        transition: all 0.8s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      }

      .siri-circle.enlarged .siri-inner {
        width: 160px;
        height: 160px;
      }

      .siri-icon {
        font-size: 3em;
        color: white;
        transition: all 0.8s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      }

      .siri-circle.enlarged .siri-icon {
        font-size: 4em;
      }

      /* Animations */
      @keyframes gradientShift {
        0% {
          background-position: 0% 50%;
        }
        50% {
          background-position: 100% 50%;
        }
        100% {
          background-position: 0% 50%;
        }
      }

      @keyframes pulse {
        0%,
        100% {
          transform: scale(1);
        }
        50% {
          transform: scale(1.02);
        }
      }

      @keyframes pulseActive {
        0%,
        100% {
          transform: scale(1);
        }
        50% {
          transform: scale(1.08);
        }
      }

      @keyframes listeningGlow {
        0%,
        100% {
          filter: brightness(1) saturate(1);
        }
        50% {
          filter: brightness(1.2) saturate(1.3);
        }
      }

      @keyframes expandingRing {
        0% {
          transform: scale(0.8);
          opacity: 0.4;
        }
        50% {
          transform: scale(1.1);
          opacity: 0.2;
        }
        100% {
          transform: scale(1.3);
          opacity: 0;
        }
      }

      /* Volume-based pulsing animations */
      @keyframes volumePulse {
        0% {
          transform: scale(1);
        }
        50% {
          transform: scale(var(--volume-scale, 1.05));
        }
        100% {
          transform: scale(1);
        }
      }

      @keyframes volumeGlow {
        0% {
          filter: brightness(1) saturate(1);
          box-shadow: 0 10px 40px rgba(0, 122, 255, 0.3);
        }
        50% {
          filter: brightness(var(--volume-brightness, 1.1)) saturate(var(--volume-saturation, 1.2));
          box-shadow: 0 15px 50px rgba(0, 122, 255, var(--volume-shadow, 0.4));
        }
        100% {
          filter: brightness(1) saturate(1);
          box-shadow: 0 10px 40px rgba(0, 122, 255, 0.3);
        }
      }

      .siri-circle.volume-pulse {
        animation: volumePulse 0.3s ease-in-out infinite, volumeGlow 0.3s ease-in-out infinite;
      }

      @keyframes fadeInUp {
        from {
          opacity: 0;
          transform: translateY(30px);
        }
        to {
          opacity: 1;
          transform: translateY(0);
        }
      }

      @keyframes typewriter {
        from {
          width: 0;
        }
        to {
          width: 100%;
        }
      }

      @keyframes blink {
        50% {
          border-color: transparent;
        }
      }

      /* Instruction Text */
      .instruction-text {
        color: #6e6e73;
        font-size: 1.1em;
        margin-top: 40px;
        font-weight: 400;
        opacity: 1;
        transform: translateY(0);
        transition: all 0.6s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      }

      .instruction-text.hidden {
        display: none;
      }

      /* Transcript and AI Response Area */
      .response-section {
        max-width: 800px;
        width: 90%;
        margin: 40px auto 0;
        opacity: 0;
        transform: translateY(30px);
        transition: all 0.8s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      }

      .response-section.visible {
        opacity: 1;
        transform: translateY(0);
      }

      /* User Transcript */
      .user-transcript {
        background: rgba(0, 122, 255, 0.1);
        backdrop-filter: blur(20px);
        border-radius: 20px;
        padding: 20px;
        margin-bottom: 20px;
        box-shadow: 0 5px 20px rgba(0, 122, 255, 0.1);
        border: 1px solid rgba(0, 122, 255, 0.2);
        text-align: left;
        position: relative;
      }

      .user-transcript-header {
        display: flex;
        align-items: center;
        margin-bottom: 15px;
        padding-bottom: 10px;
        border-bottom: 1px solid rgba(0, 122, 255, 0.2);
      }

      .user-avatar {
        width: 35px;
        height: 35px;
        border-radius: 50%;
        background: linear-gradient(45deg, #007aff, #5856d6);
        display: flex;
        align-items: center;
        justify-content: center;
        margin-right: 12px;
        font-size: 1em;
      }

      .user-name {
        font-weight: 600;
        color: #1d1d1f;
        font-size: 1em;
      }

      .user-transcript-text {
        color: #333;
        font-size: 1em;
        line-height: 1.5;
        margin: 0;
        font-style: italic;
      }

      /* AI Response Area */
      .ai-response-container {
        width: 100%;
      }

      .ai-response {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(20px);
        border-radius: 20px;
        padding: 30px;
        box-shadow: 0 10px 40px rgba(0, 0, 0, 0.1);
        border: 1px solid rgba(255, 255, 255, 0.2);
        text-align: left;
        position: relative;
      }

      .ai-response-header {
        display: flex;
        align-items: center;
        margin-bottom: 20px;
        padding-bottom: 15px;
        border-bottom: 1px solid rgba(0, 0, 0, 0.1);
      }

      .ai-avatar {
        width: 40px;
        height: 40px;
        border-radius: 50%;
        background: linear-gradient(45deg, #007aff, #5856d6);
        display: flex;
        align-items: center;
        justify-content: center;
        margin-right: 15px;
        font-size: 1.2em;
      }

      .ai-name {
        font-weight: 600;
        color: #1d1d1f;
        font-size: 1.1em;
      }

      .ai-response-text {
        color: #333;
        font-size: 1.1em;
        line-height: 1.6;
        margin: 0;
        min-height: 1.6em;
      }

      /* Markdown styling */
      .ai-response-text h1,
      .ai-response-text h2,
      .ai-response-text h3,
      .ai-response-text h4,
      .ai-response-text h5,
      .ai-response-text h6 {
        color: #1d1d1f;
        margin: 1em 0 0.5em 0;
        font-weight: 600;
      }

      .ai-response-text h1 { font-size: 1.5em; }
      .ai-response-text h2 { font-size: 1.3em; }
      .ai-response-text h3 { font-size: 1.2em; }
      .ai-response-text h4 { font-size: 1.1em; }

      .ai-response-text ul,
      .ai-response-text ol {
        margin: 0.5em 0;
        padding-left: 1.5em;
      }

      .ai-response-text li {
        margin: 0.3em 0;
      }

      .ai-response-text p {
        margin: 0.5em 0;
      }

      .ai-response-text a {
        color: #007aff;
        text-decoration: none;
        border-bottom: 1px solid rgba(0, 122, 255, 0.3);
        transition: all 0.3s ease;
      }

      .ai-response-text a:hover {
        color: #0056cc;
        border-bottom-color: #0056cc;
      }

      .ai-response-text code {
        background: rgba(0, 0, 0, 0.05);
        padding: 0.2em 0.4em;
        border-radius: 4px;
        font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace;
        font-size: 0.9em;
      }

      .ai-response-text pre {
        background: rgba(0, 0, 0, 0.05);
        padding: 1em;
        border-radius: 8px;
        overflow-x: auto;
        margin: 1em 0;
      }

      .ai-response-text pre code {
        background: none;
        padding: 0;
      }

      .ai-response-text blockquote {
        border-left: 4px solid #007aff;
        margin: 1em 0;
        padding-left: 1em;
        color: #6e6e73;
        font-style: italic;
      }

      .ai-response-text strong {
        font-weight: 600;
        color: #1d1d1f;
      }

      .ai-response-text em {
        font-style: italic;
      }

      .typing-cursor {
        display: inline-block;
        width: 3px;
        height: 1.2em;
        background-color: #007aff;
        margin-left: 2px;
        animation: blink 1s infinite;
        vertical-align: text-bottom;
      }

      /* Response Actions */
      .response-actions {
        margin-top: 20px;
        padding-top: 15px;
        border-top: 1px solid rgba(0, 0, 0, 0.1);
        display: flex;
        gap: 10px;
        justify-content: flex-end;
      }

      .action-btn {
        background: #007aff;
        color: white;
        border: none;
        border-radius: 8px;
        padding: 8px 16px;
        font-size: 0.9em;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.3s ease;
      }

      .action-btn:hover {
        background: #0056cc;
        transform: translateY(-1px);
      }

      .action-btn.secondary {
        background: rgba(0, 0, 0, 0.05);
        color: #333;
      }

      .action-btn.secondary:hover {
        background: rgba(0, 0, 0, 0.1);
      }


      /* Integration Popup */
      .integration-popup {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background: rgba(0, 0, 0, 0.5);
        display: none;
        justify-content: center;
        align-items: center;
        backdrop-filter: blur(10px);
        z-index: 1000;
      }

      .popup-content {
        background: white;
        border-radius: 20px;
        padding: 30px;
        max-width: 400px;
        width: 90%;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        text-align: center;
      }

      .popup-title {
        font-size: 1.8em;
        font-weight: 600;
        color: #1d1d1f;
        margin-bottom: 10px;
      }

      .popup-subtitle {
        color: #6e6e73;
        margin-bottom: 30px;
        font-size: 1em;
      }

      .integration-item {
        display: flex;
        align-items: center;
        padding: 15px 20px;
        margin: 10px 0;
        background: #f8f9fa;
        border-radius: 15px;
        cursor: pointer;
        transition: all 0.3s ease;
        border: 2px solid transparent;
      }

      .integration-item:hover {
        background: #e3f2fd;
        border-color: #007aff;
        transform: translateY(-2px);
      }

      .integration-item.authenticated {
        background: #e8f5e8;
        border-color: #4caf50;
        position: relative;
      }

      .integration-item.authenticated::after {
        content: 'âœ“';
        position: absolute;
        top: 10px;
        right: 15px;
        color: #4caf50;
        font-weight: bold;
        font-size: 1.2em;
      }

      .integration-item.authenticated:hover {
        background: #d4edda;
        border-color: #45a049;
      }

      .integration-icon {
        font-size: 1.5em;
        margin-right: 15px;
        width: 30px;
        text-align: center;
      }

      .integration-name {
        flex: 1;
        text-align: left;
        font-weight: 500;
        color: #1d1d1f;
      }

      .close-popup {
        position: absolute;
        top: 15px;
        right: 20px;
        background: none;
        border: none;
        font-size: 1.5em;
        color: #6e6e73;
        cursor: pointer;
        padding: 5px;
      }

      .close-popup:hover {
        color: #1d1d1f;
      }

      /* Responsive Design */
      @media (max-width: 768px) {
        .welcome-title {
          font-size: 2.5em;
        }

        .welcome-subtitle {
          font-size: 1.2em;
          margin-bottom: 60px;
        }

        .siri-circle {
          width: 150px;
          height: 150px;
        }

        .siri-circle.enlarged {
          width: 200px;
          height: 200px;
        }

        .siri-inner {
          width: 90px;
          height: 90px;
        }

        .siri-circle.enlarged .siri-inner {
          width: 120px;
          height: 120px;
        }

        .siri-icon {
          font-size: 2.5em;
        }

        .siri-circle.enlarged .siri-icon {
          font-size: 3em;
        }

        .user-transcript {
          padding: 15px;
          margin: 0 10px 15px 10px;
        }

        .ai-response {
          padding: 20px;
          margin: 0 10px;
        }

        .main-content.listening,
        .main-content.responding {
          padding-top: 20vh;
        }

        .popup-content {
          margin: 20px;
          padding: 20px;
        }
      }

      @media (max-width: 480px) {
        .welcome-title {
          font-size: 2em;
        }

        .welcome-subtitle {
          font-size: 1em;
        }

        .siri-circle {
          width: 120px;
          height: 120px;
        }

        .siri-circle.enlarged {
          width: 160px;
          height: 160px;
        }

        .siri-inner {
          width: 70px;
          height: 70px;
        }

        .siri-circle.enlarged .siri-inner {
          width: 90px;
          height: 90px;
        }

        .siri-icon {
          font-size: 2em;
        }

        .siri-circle.enlarged .siri-icon {
          font-size: 2.5em;
        }

        .integration-btn {
          top: 10px;
          right: 10px;
          padding: 8px 15px;
          font-size: 13px;
        }
      }
    </style>
  </head>
  <body>
    <!-- Integration Button - Top Right -->
    <button class="integration-btn" onclick="openIntegrationPopup()">
      Integrate with apps
    </button>

    <!-- Main Content -->
    <div class="main-content" id="mainContent">
      <h1 class="welcome-title">Well come to Vocal Agent!</h1>
      <p class="welcome-subtitle">what do you need help with?</p>

      <!-- Siri-like Animated Circle -->
      <div class="siri-container">
        <div class="siri-circle" id="siriCircle" onclick="toggleListening()">
          <div class="siri-inner">
            <div class="siri-icon">ðŸŽ¤</div>
          </div>
        </div>
      </div>

      <p class="instruction-text" id="instructionText">
        Click to start listening, click again to stop
      </p>

      <!-- Response Section (Transcript + AI Response) -->
      <div class="response-section" id="responseSection">
        <!-- User Transcript -->
        <div class="user-transcript" id="userTranscript" style="display: none">
          <div class="user-transcript-header">
            <div class="user-avatar">ðŸ‘¤</div>
            <div class="user-name">You said</div>
          </div>
          <p class="user-transcript-text" id="userTranscriptText"></p>
        </div>

        <!-- AI Response Container -->
        <div class="ai-response-container">
          <div class="ai-response">
            <div class="ai-response-header">
              <div class="ai-avatar">ðŸ¤–</div>
              <div class="ai-name">Iris</div>
            </div>
            <p class="ai-response-text" id="aiResponseText"></p>
            <div
              class="response-actions"
              id="responseActions"
              style="display: none"
            >
              <button class="action-btn secondary" onclick="clearResponse()">
                Clear
              </button>
              <button class="action-btn" onclick="startNewCommand()">
                Ask Again
              </button>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Integration Popup -->
    <div class="integration-popup" id="integrationPopup">
      <div class="popup-content">
        <button class="close-popup" onclick="closeIntegrationPopup()">âœ•</button>
        <h2 class="popup-title">Integrate With Apps</h2>
        <p class="popup-subtitle">Integrate with 3rd party apps:</p>

        <div
          class="integration-item"
          onclick="handleIntegration('Google Calendar')"
        >
          <div class="integration-icon">ðŸ“…</div>
          <div class="integration-name">Google Calendar</div>
        </div>

        <div class="integration-item" onclick="handleIntegration('Notes')">
          <div class="integration-icon">ï¿½</div>
          <div class="integration-name">Notes</div>
        </div>

        <div class="integration-item" onclick="handleIntegration('Gmail')">
          <div class="integration-icon">ðŸ“§</div>
          <div class="integration-name">Gmail</div>
        </div>

        <div class="integration-item" onclick="handleIntegration('Spotify')">
          <div class="integration-icon">ðŸŽµ</div>
          <div class="integration-name">Spotify</div>
        </div>
      </div>
    </div>

    <script>
      let isListening = false
      let recognition = null
      let finalTranscript = ''
      let currentState = 'idle' // 'idle', 'listening', 'processing', 'responding'
      let typingTimer = null
      let currentAudio = null
      let currentResponseText = ''
      let preparedAudioUrl = null
      
      // Volume detection variables
      let audioContext = null
      let microphone = null
      let analyser = null
      let dataArray = null
      let volumeAnimationId = null
      let currentVolume = 0
      let targetVolume = 0
      let volumeSmoothing = 0.1

      // State Management Functions
      function setState(newState) {
        console.log(`State transition: ${currentState} â†’ ${newState}`)
        currentState = newState

        const mainContent = document.getElementById('mainContent')
        const welcomeTitle = document.querySelector('.welcome-title')
        const welcomeSubtitle = document.querySelector('.welcome-subtitle')
        const siriContainer = document.querySelector('.siri-container')
        const siriCircle = document.getElementById('siriCircle')
        const instructionText = document.getElementById('instructionText')
        const responseSection = document.getElementById('responseSection')
        const userTranscript = document.getElementById('userTranscript')

        // Remove all state classes first
        mainContent.classList.remove('listening', 'responding')
        welcomeTitle.classList.remove('hidden')
        welcomeSubtitle.classList.remove('hidden')
        siriContainer.classList.remove('enlarged')
        siriCircle.classList.remove('listening', 'enlarged')
        instructionText.classList.remove('hidden')
        responseSection.classList.remove('visible')
        userTranscript.style.display = 'none'

        switch (newState) {
          case 'idle':
            instructionText.textContent =
              'Click to start listening, click again to stop'
            break

          case 'listening':
            mainContent.classList.add('listening')
            welcomeTitle.classList.add('hidden')
            welcomeSubtitle.classList.add('hidden')
            siriContainer.classList.add('enlarged')
            siriCircle.classList.add('listening', 'enlarged')
            instructionText.textContent =
              'Listening... Click again to stop and process'
            break

          case 'processing':
            mainContent.classList.add('listening')
            welcomeTitle.classList.add('hidden')
            welcomeSubtitle.classList.add('hidden')
            siriContainer.classList.add('enlarged')
            siriCircle.classList.add('enlarged')
            siriCircle.classList.remove('listening')
            instructionText.textContent = 'Processing your request...'
            break

          case 'responding':
            mainContent.classList.add('responding')
            welcomeTitle.classList.add('hidden')
            welcomeSubtitle.classList.add('hidden')
            instructionText.classList.add('hidden')
            siriContainer.classList.add('enlarged')
            siriCircle.classList.add('enlarged')
            siriCircle.classList.remove('listening')
            responseSection.classList.add('visible')
            break
        }
      }

      // Typing Animation Function with Markdown Support
      function typeText(element, text, speed = 50) {
        return new Promise((resolve) => {
          // Check if text contains markdown
          const hasMarkdown = /[#*`\[\]()_~>|]/.test(text)
          
          if (hasMarkdown) {
            // For markdown content, render it directly without typing animation
            element.innerHTML = marked.parse(text)
            resolve()
          } else {
            // For plain text, use the original typing animation
            element.textContent = ''
            const cursor = document.createElement('span')
            cursor.className = 'typing-cursor'
            element.appendChild(cursor)

            let i = 0
            const words = text.split(' ')

            function typeWord() {
              if (i < words.length) {
                const currentText = words.slice(0, i + 1).join(' ')
                element.textContent = currentText
                element.appendChild(cursor)
                i++
                typingTimer = setTimeout(typeWord, speed + Math.random() * 30)
              } else {
                cursor.remove()
                resolve()
              }
            }

            typeWord()
          }
        })
      }

      // Clear typing animation
      function clearTyping() {
        if (typingTimer) {
          clearTimeout(typingTimer)
          typingTimer = null
        }
      }

      // Check if the response indicates a Spotify integration error
      function isSpotifyIntegrationError(responseText) {
        const lowerResponse = responseText.toLowerCase()
        
        // Specific Spotify error patterns
        const spotifyErrorPatterns = [
          'spotify.*not.*connected',
          'spotify.*not.*authenticated',
          'spotify.*authentication.*failed',
          'spotify.*authorization.*required',
          'spotify.*login.*required',
          'spotify.*permission.*denied',
          'spotify.*access.*denied',
          'spotify.*token.*expired',
          'spotify.*invalid.*token',
          'unable.*to.*access.*spotify',
          'cannot.*connect.*to.*spotify',
          'spotify.*integration.*failed',
          'spotify.*api.*error',
          'spotify.*service.*unavailable',
          'trouble.*connecting.*to.*music.*service',
          'having.*trouble.*connecting.*to.*music',
          'music.*service.*unavailable',
          'spotify.*agent.*not.*available',
          'spotify.*agent.*connection.*failed',
          'cannot.*reach.*spotify.*agent',
          'spotify.*agent.*timeout',
          'spotify.*agent.*error',
          'try.*again.*later',
          'music.*service.*down',
          'spotify.*service.*down',
          'connection.*refused',
          'connection.*timeout',
          'service.*unavailable',
          'not authenticated',
          'authentication failed',
          'authorization required',
          'login required',
          'permission denied',
          'access denied',
          'token expired',
          'invalid token',
          'unable to access',
          'cannot connect',
          'integration failed',
          'api error',
          'service unavailable',
          'trouble connecting',
          'connection failed',
          'agent not available',
          'agent connection failed',
          'cannot reach',
          'timeout',
          'connection refused',
          'service down',
          'unreachable'
        ]
        
        // Check for specific error patterns first
        const hasSpecificError = spotifyErrorPatterns.some(pattern => {
          const regex = new RegExp(pattern, 'i')
          return regex.test(lowerResponse)
        })
        
        if (hasSpecificError) {
          return true
        }
        
        // Fallback: Check for Spotify-related terms AND error terms
        const spotifyErrorKeywords = [
          'spotify',
          'music',
          'play',
          'song',
          'playlist',
          'album',
          'artist',
          'service',
          'agent'
        ]
        
        const errorKeywords = [
          'error',
          'failed',
          'unable',
          'cannot',
          'not available',
          'not connected',
          'authentication',
          'authorization',
          'permission',
          'denied',
          'expired',
          'invalid',
          'trouble',
          'connecting',
          'timeout',
          'unreachable'
        ]
        
        const hasSpotifyTerms = spotifyErrorKeywords.some(keyword => 
          lowerResponse.includes(keyword)
        )
        const hasErrorTerms = errorKeywords.some(keyword => 
          lowerResponse.includes(keyword)
        )
        
        return hasSpotifyTerms && hasErrorTerms
      }

      // Add Spotify connection prompt to error messages
      function addSpotifyConnectionPrompt(responseText) {
        // Check if the response already contains integration guidance
        if (responseText.toLowerCase().includes('integrate with apps') || 
            responseText.toLowerCase().includes('top right corner')) {
          return responseText // Don't add duplicate guidance
        }
        
        const connectionPrompt = '\n\nðŸŽµ To use Spotify features, please click the "Integrate with apps" button in the top right corner and connect your Spotify account.'
        return responseText + connectionPrompt
      }

      // Volume Detection Functions
      async function initializeVolumeDetection() {
        try {
          // Request microphone access
          const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true
            } 
          })
          
          // Create audio context
          audioContext = new (window.AudioContext || window.webkitAudioContext)()
          microphone = audioContext.createMediaStreamSource(stream)
          analyser = audioContext.createAnalyser()
          
          // Configure analyser
          analyser.fftSize = 256
          analyser.smoothingTimeConstant = 0.8
          const bufferLength = analyser.frequencyBinCount
          dataArray = new Uint8Array(bufferLength)
          
          // Connect microphone to analyser
          microphone.connect(analyser)
          
          console.log('Volume detection initialized successfully')
          return true
        } catch (error) {
          console.warn('Volume detection initialization failed:', error)
          return false
        }
      }

      function startVolumeMonitoring() {
        if (!analyser || !dataArray) {
          console.warn('Volume monitoring not available - analyser or dataArray missing')
          return
        }
        
        console.log('Starting microphone volume monitoring...')
        
        function updateVolume() {
          analyser.getByteFrequencyData(dataArray)
          
          // Calculate average volume
          let sum = 0
          for (let i = 0; i < dataArray.length; i++) {
            sum += dataArray[i]
          }
          const average = sum / dataArray.length
          
          // Convert to 0-1 range and apply smoothing
          targetVolume = Math.min(average / 128, 1)
          currentVolume += (targetVolume - currentVolume) * volumeSmoothing
          
          // Debug logging (only log occasionally to avoid spam)
          if (Math.random() < 0.01) { // Log 1% of the time
            console.log(`Mic Volume: ${currentVolume.toFixed(3)}`)
          }
          
          // Update circle animation based on volume
          updateCircleVolumeAnimation(currentVolume)
          
          volumeAnimationId = requestAnimationFrame(updateVolume)
        }
        
        updateVolume()
      }

      function stopVolumeMonitoring() {
        if (volumeAnimationId) {
          cancelAnimationFrame(volumeAnimationId)
          volumeAnimationId = null
        }
        
        // Reset volume
        currentVolume = 0
        targetVolume = 0
        updateCircleVolumeAnimation(0)
      }

      function updateCircleVolumeAnimation(volume) {
        const siriCircle = document.getElementById('siriCircle')
        if (!siriCircle) return
        
        // Only apply volume animation when listening
        if (currentState === 'listening') {
          // Calculate animation properties based on volume
          const scale = 1 + (volume * 0.3) // Scale from 1.0 to 1.3
          const brightness = 1 + (volume * 0.4) // Brightness from 1.0 to 1.4
          const saturation = 1 + (volume * 0.5) // Saturation from 1.0 to 1.5
          const shadow = 0.3 + (volume * 0.4) // Shadow opacity from 0.3 to 0.7
          
          // Set CSS custom properties
          siriCircle.style.setProperty('--volume-scale', scale)
          siriCircle.style.setProperty('--volume-brightness', brightness)
          siriCircle.style.setProperty('--volume-saturation', saturation)
          siriCircle.style.setProperty('--volume-shadow', shadow)
          
          // Add volume pulse class if volume is above threshold
          if (volume > 0.1) {
            siriCircle.classList.add('volume-pulse')
            // Debug logging
            if (Math.random() < 0.05) { // Log 5% of the time when pulsing
              console.log(`Mic volume pulsing: ${volume.toFixed(3)}`)
            }
          } else {
            siriCircle.classList.remove('volume-pulse')
          }
        } else {
          // Remove volume pulse when not listening
          siriCircle.classList.remove('volume-pulse')
        }
      }

      function updateCircleTTSAnimation(volume) {
        const siriCircle = document.getElementById('siriCircle')
        if (!siriCircle) return
        
        // Apply TTS volume animation when responding
        if (currentState === 'responding') {
          // Calculate animation properties based on TTS volume
          const scale = 1 + (volume * 0.2) // Scale from 1.0 to 1.2 (more subtle than mic)
          const brightness = 1 + (volume * 0.3) // Brightness from 1.0 to 1.3
          const saturation = 1 + (volume * 0.4) // Saturation from 1.0 to 1.4
          const shadow = 0.3 + (volume * 0.3) // Shadow opacity from 0.3 to 0.6
          
          // Set CSS custom properties
          siriCircle.style.setProperty('--volume-scale', scale)
          siriCircle.style.setProperty('--volume-brightness', brightness)
          siriCircle.style.setProperty('--volume-saturation', saturation)
          siriCircle.style.setProperty('--volume-shadow', shadow)
          
          // Add volume pulse class if volume is above threshold
          if (volume > 0.05) {
            siriCircle.classList.add('volume-pulse')
            // Debug logging
            if (Math.random() < 0.1) { // Log 10% of the time when pulsing
              console.log(`TTS volume pulsing: ${volume.toFixed(3)}`)
            }
          } else {
            siriCircle.classList.remove('volume-pulse')
          }
        }
      }

      function setupFallbackTTSVolumeMonitoring() {
        if (!currentAudio) return
        
        console.log('Setting up fallback TTS volume monitoring...')
        
        // Simulate TTS volume with a pulsing pattern
        let fallbackVolumeId = null
        let pulsePhase = 0
        
        function simulateTTSVolume() {
          // Create a pulsing pattern that simulates speech rhythm
          const baseVolume = 0.3 + Math.sin(pulsePhase) * 0.2
          const randomVariation = Math.random() * 0.1
          const simulatedVolume = Math.min(baseVolume + randomVariation, 0.8)
          
          pulsePhase += 0.3
          
          console.log(`Fallback TTS Volume: ${simulatedVolume.toFixed(3)}`)
          
          // Update circle animation
          updateCircleTTSAnimation(simulatedVolume)
          
          if (!currentAudio.paused) {
            fallbackVolumeId = requestAnimationFrame(simulateTTSVolume)
          }
        }
        
        // Start monitoring when audio starts playing
        currentAudio.addEventListener('play', () => {
          console.log('TTS audio started, beginning fallback volume monitoring...')
          simulateTTSVolume()
        })
        
        // Stop monitoring when audio ends
        currentAudio.addEventListener('ended', () => {
          console.log('TTS audio ended, stopping fallback volume monitoring...')
          if (fallbackVolumeId) {
            cancelAnimationFrame(fallbackVolumeId)
            fallbackVolumeId = null
          }
          updateCircleTTSAnimation(0)
        })
      }

      // Initialize Web Speech API
      function initializeSpeechRecognition() {
        try {
          // Check for browser support
          const SpeechRecognition =
            window.SpeechRecognition || window.webkitSpeechRecognition

          if (!SpeechRecognition) {
            console.error('Speech recognition not supported in this browser')
            return false
          }

          recognition = new SpeechRecognition()
          recognition.continuous = true
          recognition.interimResults = true
          recognition.lang = 'en-US'

          recognition.onstart = () => {
            console.log('Speech recognition started')
          }

          recognition.onresult = (event) => {
            let interimTranscript = ''
            finalTranscript = ''

            for (let i = event.resultIndex; i < event.results.length; i++) {
              const transcript = event.results[i][0].transcript
              if (event.results[i].isFinal) {
                finalTranscript += transcript
              } else {
                interimTranscript += transcript
              }
            }

            console.log('Interim:', interimTranscript)
            console.log('Final so far:', finalTranscript)
          }

          recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error)
          }

          recognition.onend = () => {
            console.log('Speech recognition ended')
            if (finalTranscript.trim()) {
              processTranscribedText(finalTranscript.trim())
            }
          }

          return true
        } catch (error) {
          console.error('Error initializing speech recognition:', error)
          return false
        }
      }

      // Toggle listening state for Siri circle
      async function toggleListening() {
        if (currentState === 'processing') {
          return // Don't allow interruption during processing
        }

        // If in responding state, start a new request
        if (currentState === 'responding') {
          startNewRequest()
          return
        }

        if (!isListening) {
          // Start listening
          if (!recognition && !initializeSpeechRecognition()) {
            alert('Speech recognition not supported or failed to initialize')
            return
          }

          // Initialize volume detection if not already done
          if (!audioContext) {
            await initializeVolumeDetection()
          }

          finalTranscript = ''
          recognition.start()
          isListening = true
          setState('listening')
          startVolumeMonitoring()
          console.log('Started listening...')
        } else {
          // Stop listening and start processing
          recognition.stop()
          isListening = false
          setState('processing')
          stopVolumeMonitoring()
          console.log('Stopped listening, starting processing...')
        }
      }

      // Start a new request from responding state
      async function startNewRequest() {
        clearTyping()
        const responseActions = document.getElementById('responseActions')
        responseActions.style.display = 'none'

        console.log('Starting new request from responding state...')

        // Immediately start listening without going to idle first
        if (!recognition && !initializeSpeechRecognition()) {
          alert('Speech recognition not supported or failed to initialize')
          return
        }

        // Initialize volume detection if not already done
        if (!audioContext) {
          await initializeVolumeDetection()
        }

        finalTranscript = ''
        recognition.start()
        isListening = true
        setState('listening')
        startVolumeMonitoring()
        console.log('New request started directly from responding state')
      }

      // Process transcribed text through the voice pipeline
      async function processTranscribedText(transcribedText) {
        try {
          console.log('Processing speech through direct Gemini response...')
          console.log('Transcribed:', transcribedText)

          // Get direct response from Gemini
          const geminiResponse = await getGeminiDirectResponse(transcribedText)
          if (!geminiResponse.success) {
            throw new Error(geminiResponse.error)
          }

          console.log('Gemini Response:', geminiResponse.gemini_response)

          // Show results with typing animation
          await displayResponseWithTyping({
            voice_input: transcribedText,
            gemini_response: geminiResponse.gemini_response,
          })
        } catch (error) {
          console.error('Voice processing error:', error)

          // Show error with typing animation
          await displayResponseWithTyping({
            error: true,
            message: `I encountered an error: ${error.message}. Please try again.`,
          })
        }
      }

      // Speech recognition now handled by Web Speech API above

      // Call Gemini direct response API
      async function getGeminiDirectResponse(voiceInput) {
        const response = await fetch('/api/gemini-direct-response', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ voice_input: voiceInput }),
        })
        return await response.json()
      }

      // Call Gemini refinement API (kept for backward compatibility)
      async function refineSpeech(rawSpeech) {
        const response = await fetch('/api/refine-speech', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ raw_speech: rawSpeech }),
        })
        return await response.json()
      }

      // Call ASI:One processing API (kept for backward compatibility)
      async function processCommand(refinedCommand) {
        const response = await fetch('/api/process-command', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ refined_command: refinedCommand }),
        })
        return await response.json()
      }

      // Display response with typing animation
      async function displayResponseWithTyping(results) {
        setState('responding')

        const aiResponseText = document.getElementById('aiResponseText')
        const responseActions = document.getElementById('responseActions')
        const responseSection = document.getElementById('responseSection')
        const userTranscript = document.getElementById('userTranscript')
        const userTranscriptText = document.getElementById('userTranscriptText')

        // Show the transcript if we have voice input
        if (results.voice_input) {
          userTranscriptText.textContent = results.voice_input
          userTranscript.style.display = 'block'
        } else {
          userTranscript.style.display = 'none'
        }

        let responseText = ''

        if (results.error) {
          responseText = results.message
          
          // Check if it's a Spotify-related error
          if (isSpotifyIntegrationError(responseText)) {
            responseText = addSpotifyConnectionPrompt(responseText)
          }
        } else if (results.gemini_response) {
          // New direct Gemini response format
          responseText = results.gemini_response
          
          // Check if the response indicates Spotify integration issues
          if (isSpotifyIntegrationError(responseText)) {
            responseText = addSpotifyConnectionPrompt(responseText)
          }
        } else if (results.asi_response) {
          // Legacy ASI response format (kept for backward compatibility)
          responseText =
            results.asi_response.suggested_action ||
            `I understand you want to: ${results.refined_command}. How can I help you proceed?`
        } else {
          responseText = "I'm not sure how to respond to that. Could you try again?"
        }

        // Wait for the response section to become visible, then scroll to ensure it's in view
        setTimeout(() => {
          scrollToResponseArea()
        }, 400) // Wait for the state transition to start

        // Prepare TTS first, then show text and play audio together
        if (responseText && responseText.trim()) {
          currentResponseText = responseText
          
          // Generate TTS audio first
          try {
            console.log('Preparing TTS audio...')
            await prepareTTSAudio()
            
            // Once audio is ready, start typing animation and play audio simultaneously
            console.log('Audio ready, starting synchronized text and audio...')
            await Promise.all([
              typeText(aiResponseText, responseText, 80),
              playPreparedAudio()
            ])
            
          } catch (error) {
            console.warn('TTS preparation failed, showing text without audio:', error)
            // Fallback: show text without audio if TTS fails
            await typeText(aiResponseText, responseText, 80)
          }
        } else {
          // No text to convert, just show empty response
          await typeText(aiResponseText, responseText, 80)
        }

        // Show action buttons after everything is complete
        setTimeout(() => {
          responseActions.style.display = 'flex'
        }, 500)
      }

      // Scroll to ensure the response area is fully visible
      function scrollToResponseArea() {
        const responseSection = document.getElementById('responseSection')
        if (!responseSection) return

        const containerRect = responseSection.getBoundingClientRect()
        const windowHeight = window.innerHeight

        // Check if the response section is fully visible
        const isFullyVisible =
          containerRect.top >= 0 && containerRect.bottom <= windowHeight

        if (!isFullyVisible) {
          // Calculate the ideal scroll position to center the response area in the lower part of the screen
          const idealTop = windowHeight * 0.2 // Position response area at 20% from top of viewport
          const currentTop = containerRect.top
          const scrollOffset = currentTop - idealTop

          // Smooth scroll to the calculated position
          window.scrollBy({
            top: scrollOffset,
            behavior: 'smooth',
          })
        }
      }

      // Legacy display function (keeping for compatibility)
      function displayResults(results) {
        displayResponseWithTyping(results)
      }

      // Integration popup functions
      async function openIntegrationPopup() {
        const popup = document.getElementById('integrationPopup')
        popup.style.display = 'flex'
        
        // Check authentication status when opening popup
        await checkAuthenticationStatus()
      }

      function closeIntegrationPopup() {
        const popup = document.getElementById('integrationPopup')
        popup.style.display = 'none'
      }

      // Check authentication status for all apps
      async function checkAuthenticationStatus() {
        try {
          // Check Spotify authentication
          const spotifyResponse = await fetch('/api/spotify/status')
          const spotifyData = await spotifyResponse.json()
          
          const spotifyItem = document.querySelector('.integration-item[onclick*="Spotify"]')
          if (spotifyItem) {
            if (spotifyData.authenticated) {
              spotifyItem.classList.add('authenticated')
              console.log(`âœ… Spotify authenticated as: ${spotifyData.user?.display_name || 'Unknown'}`)
            } else {
              spotifyItem.classList.remove('authenticated')
              console.log(`âŒ Spotify not authenticated: ${spotifyData.message || spotifyData.error}`)
            }
          }
          
          // Check Gmail authentication
          try {
            const systemResponse = await fetch('/api/system-info')
            const systemData = await systemResponse.json()
            
            const gmailItem = document.querySelector('.integration-item[onclick*="Gmail"]')
            if (gmailItem && systemData.success && systemData.system_info) {
              const gmailStatus = systemData.system_info.current_authentications?.gmail
              
              if (gmailStatus?.authenticated) {
                gmailItem.classList.add('authenticated')
                console.log(`âœ… Gmail authenticated and connected`)
              } else {
                gmailItem.classList.remove('authenticated')
                console.log(`âŒ Gmail not authenticated: ${gmailStatus?.error || 'Not connected'}`)
              }
            }
          } catch (gmailError) {
            console.error('Error checking Gmail status:', gmailError)
            const gmailItem = document.querySelector('.integration-item[onclick*="Gmail"]')
            if (gmailItem) {
              gmailItem.classList.remove('authenticated')
            }
          }
          
          // For other apps, remove authenticated status
          const otherItems = document.querySelectorAll('.integration-item:not([onclick*="Spotify"]):not([onclick*="Gmail"])')
          otherItems.forEach(item => {
            item.classList.remove('authenticated')
          })
          
        } catch (error) {
          console.error('Error checking authentication status:', error)
        }
      }

      // Handle integration clicks
      async function handleIntegration(appName) {
        console.log(`click on Integration: ${appName}`)
        
        if (appName === 'Spotify') {
          await handleSpotifyIntegration()
        } else if (appName === 'Gmail') {
          await handleGmailIntegration()
        } else {
          alert(`Integration with ${appName} is coming soon!`)
        }
        
        closeIntegrationPopup()
      }

      // Handle Spotify integration
      async function handleSpotifyIntegration() {
        try {
          console.log('Starting Spotify authentication...')
          
          // Show loading state
          const spotifyItem = document.querySelector('.integration-item[onclick*="Spotify"]')
          if (spotifyItem) {
            spotifyItem.style.opacity = '0.6'
            spotifyItem.style.pointerEvents = 'none'
            const originalText = spotifyItem.querySelector('.integration-name').textContent
            spotifyItem.querySelector('.integration-name').textContent = 'Connecting...'
          }
          
          // Call the backend to get Spotify auth URL
          const response = await fetch('/api/spotify/auth')
          const data = await response.json()
          
          if (data.success && data.auth_url) {
            console.log('Redirecting to Spotify authentication...')
            // Redirect to Spotify OAuth
            window.location.href = data.auth_url
          } else {
            throw new Error(data.error || 'Failed to get Spotify authentication URL')
          }
          
        } catch (error) {
          console.error('Spotify integration error:', error)
          alert(`Spotify integration failed: ${error.message}`)
          
          // Reset UI state
          const spotifyItem = document.querySelector('.integration-item[onclick*="Spotify"]')
          if (spotifyItem) {
            spotifyItem.style.opacity = ''
            spotifyItem.style.pointerEvents = ''
            spotifyItem.querySelector('.integration-name').textContent = 'Spotify'
          }
        }
      }

      // Handle Gmail integration
      async function handleGmailIntegration() {
        try {
          console.log('Starting Gmail integration...')
          
          // Show loading state
          const gmailItem = document.querySelector('.integration-item[onclick*="Gmail"]')
          if (gmailItem) {
            gmailItem.style.opacity = '0.6'
            gmailItem.style.pointerEvents = 'none'
            const originalText = gmailItem.querySelector('.integration-name').textContent
            gmailItem.querySelector('.integration-name').textContent = 'Connecting...'
          }
          
          // Check Gmail agent status
          const response = await fetch('/api/system-info')
          const data = await response.json()
          
          if (data.success && data.system_info) {
            const gmailStatus = data.system_info.current_authentications?.gmail
            
            if (gmailStatus?.authenticated) {
              console.log('Gmail is already authenticated and connected!')
              alert('âœ… Gmail is already connected and ready to use!\n\nYou can now send emails by saying things like:\nâ€¢ "Send an email to john@example.com about the meeting"\nâ€¢ "Compose a thank you email to the team"\nâ€¢ "Email the client with the project update"')
            } else {
              // Gmail agent is not authenticated, get authentication URL
              console.log('Gmail agent needs authentication')
              
              try {
                // Get Gmail authentication URL from backend
                const authResponse = await fetch('/api/gmail/auth')
                const authData = await authResponse.json()
                
                if (authData.success && authData.auth_url) {
                  // Show dialog with authentication link
                  const userConfirmed = confirm(
                    'ðŸ“§ Gmail Authentication Required\n\n' +
                    'To use Gmail features, you need to authenticate with Google.\n\n' +
                    'Click OK to open the authentication page in a new tab.\n\n' +
                    'After authentication, you can send emails through voice commands!'
                  )
                  
                  if (userConfirmed) {
                    // Open authentication page in new tab
                    window.open(authData.auth_url, '_blank')
                    
                    // Show additional instructions
                    setTimeout(() => {
                      alert(
                        'ðŸ”— Authentication page opened!\n\n' +
                        'Steps to complete authentication:\n' +
                        '1. Complete the Google OAuth flow in the new tab\n' +
                        '2. Return here and click the Gmail button again\n' +
                        '3. The button should turn green when authenticated\n\n' +
                        'Then you can send emails by saying:\n' +
                        '"Send an email to test@example.com about the meeting"'
                      )
                    }, 1000)
                  }
                } else {
                  throw new Error(authData.error || 'Failed to get Gmail authentication URL')
                }
              } catch (authError) {
                console.error('Gmail auth URL error:', authError)
                alert(
                  'âŒ Gmail Authentication Setup Failed\n\n' +
                  `Error: ${authError.message}\n\n` +
                  'Please make sure:\n' +
                  '1. The Gmail agent is running on port 8000\n' +
                  '2. The Gmail OAuth server is running on port 8080\n' +
                  '3. Try restarting the Gmail agent'
                )
              }
            }
          } else {
            throw new Error('Failed to get system information')
          }
          
        } catch (error) {
          console.error('Gmail integration error:', error)
          alert(`Gmail integration check failed: ${error.message}\n\nMake sure the Gmail agent is running on port 8000.`)
          
        } finally {
          // Reset UI state
          const gmailItem = document.querySelector('.integration-item[onclick*="Gmail"]')
          if (gmailItem) {
            gmailItem.style.opacity = ''
            gmailItem.style.pointerEvents = ''
            gmailItem.querySelector('.integration-name').textContent = 'Gmail'
          }
          
          // Refresh authentication status to update button styling
          checkAuthenticationStatus()
        }
      }

      // Smooth scroll to top of page
      function scrollToTop() {
        window.scrollTo({
          top: 0,
          behavior: 'smooth',
        })
      }

      // Response action functions
      function clearResponse() {
        clearTyping()
        stopTTS() // Stop any playing audio
        stopVolumeMonitoring() // Stop volume monitoring
        setState('idle')
        const responseActions = document.getElementById('responseActions')
        responseActions.style.display = 'none'
        currentResponseText = '' // Clear the stored response text

        // Scroll back to top when returning to idle
        setTimeout(() => {
          scrollToTop()
        }, 300)

        console.log('Response cleared, returning to idle state')
      }

      function startNewCommand() {
        clearTyping()
        stopTTS() // Stop any playing audio
        stopVolumeMonitoring() // Stop volume monitoring
        setState('idle')
        const responseActions = document.getElementById('responseActions')
        responseActions.style.display = 'none'
        currentResponseText = '' // Clear the stored response text

        // Scroll back to top when returning to idle
        setTimeout(() => {
          scrollToTop()
        }, 200)

        // Auto-start listening after scrolling
        setTimeout(() => {
          toggleListening()
        }, 700)

        console.log('Starting new command...')
      }

      // Close popup when clicking outside
      document
        .getElementById('integrationPopup')
        .addEventListener('click', function (e) {
          if (e.target === this) {
            closeIntegrationPopup()
          }
        })

      // Keyboard shortcut listener (cmd + space)
      document.addEventListener('keydown', function (e) {
        if ((e.metaKey || e.ctrlKey) && e.code === 'Space') {
          e.preventDefault()

          if (currentState === 'responding') {
            startNewRequest()
          } else if (currentState === 'idle' || currentState === 'listening') {
            toggleListening()
          }
        }
      })

      // Add hover feedback for responding state
      function setupButtonHoverFeedback() {
        const siriCircle = document.getElementById('siriCircle')

        // siriCircle.addEventListener('mouseenter', function () {
        //   if (currentState === 'responding') {
        //     // Show temporary instruction when hovering in responding state
        //     const instructionText = document.getElementById('instructionText')
        //     if (instructionText.classList.contains('hidden')) {
        //       instructionText.textContent = 'Click to start a new request'
        //       instructionText.classList.remove('hidden')
        //       instructionText.style.opacity = '0.8'
        //       instructionText.style.fontSize = '0.9em'
        //     }
        //   }
        // })

        siriCircle.addEventListener('mouseleave', function () {
          if (currentState === 'responding') {
            // Hide instruction when not hovering
            const instructionText = document.getElementById('instructionText')
            if (!instructionText.classList.contains('hidden')) {
              instructionText.classList.add('hidden')
              instructionText.style.opacity = ''
              instructionText.style.fontSize = ''
            }
          }
        })
      }

      // Handle Spotify authentication callback
      function handleSpotifyCallback() {
        const urlParams = new URLSearchParams(window.location.search)
        const spotifyAuth = urlParams.get('spotify_auth')
        
        if (spotifyAuth === 'success') {
          console.log('Spotify authentication successful!')
          // Show success message
          setTimeout(() => {
            alert('ðŸŽ‰ Spotify integration successful! You can now use voice commands to control your music.')
          }, 500)
          
          // Refresh authentication status
          checkAuthenticationStatus()
          
          // Clean up URL
          window.history.replaceState({}, document.title, window.location.pathname)
        } else if (spotifyAuth === 'error') {
          console.log('Spotify authentication failed')
          // Show error message
          setTimeout(() => {
            alert('âŒ Spotify authentication failed. Please try again.')
          }, 500)
          
          // Clean up URL
          window.history.replaceState({}, document.title, window.location.pathname)
        }
      }

      // Test markdown rendering function (for development/testing)
      function testMarkdownRendering() {
        const testMarkdown = `# Test Markdown Rendering

This is a **bold** statement and this is *italic* text.

Here's a list of features:
- **Bold text** for emphasis
- *Italic text* for subtle emphasis
- \`Code formatting\` for technical terms
- [Links](https://example.com) for external resources

> This is a blockquote for important notes

## Code Example
\`\`\`javascript
function test() {
  console.log("Hello, World!");
}
\`\`\`

**Numbered steps:**
1. First step
2. Second step
3. Third step

That's it! The markdown should render properly.`

        displayResponseWithTyping({
          gemini_response: testMarkdown
        })
      }

      // Make test function available globally for console testing
      window.testMarkdownRendering = testMarkdownRendering

      // TTS Functions
      async function prepareTTSAudio() {
        if (!currentResponseText || currentResponseText.trim() === '') {
          throw new Error('No response text available for TTS')
        }

        // Clean up any existing prepared audio
        if (preparedAudioUrl) {
          URL.revokeObjectURL(preparedAudioUrl)
          preparedAudioUrl = null
        }

        console.log('Converting text to speech...')
        
        // Call the TTS API
        const response = await fetch('/api/text-to-speech', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            text: currentResponseText,
            voice_id: 'JBFqnCBsd6RMkjVDRZzb', // Default voice
            model_id: 'eleven_multilingual_v2',
            output_format: 'mp3_44100_128'
          }),
        })

        const data = await response.json()

        if (!data.success) {
          throw new Error(data.error || 'TTS conversion failed')
        }

        // Create audio blob and URL for later playback
        const audioBlob = new Blob([Uint8Array.from(atob(data.audio_data), c => c.charCodeAt(0))], {
          type: 'audio/mpeg'
        })
        preparedAudioUrl = URL.createObjectURL(audioBlob)
        
        console.log('TTS audio prepared successfully')
      }

      async function playPreparedAudio() {
        if (!preparedAudioUrl) {
          throw new Error('No prepared audio available')
        }

        // Stop any currently playing audio
        if (currentAudio) {
          currentAudio.pause()
          currentAudio = null
        }

        // Create and play the prepared audio
        currentAudio = new Audio(preparedAudioUrl)
        
        // Set up TTS volume monitoring
        if (audioContext && currentAudio) {
          try {
            console.log('Setting up TTS volume monitoring...')
            
            // Create audio source from the playing audio
            const audioSource = audioContext.createMediaElementSource(currentAudio)
            const ttsAnalyser = audioContext.createAnalyser()
            ttsAnalyser.fftSize = 256
            ttsAnalyser.smoothingTimeConstant = 0.8
            
            // Connect audio source to analyser and then to destination
            audioSource.connect(ttsAnalyser)
            ttsAnalyser.connect(audioContext.destination)
            
            // Monitor TTS volume
            const ttsDataArray = new Uint8Array(ttsAnalyser.frequencyBinCount)
            let ttsVolumeId = null
            
            function monitorTTSVolume() {
              ttsAnalyser.getByteFrequencyData(ttsDataArray)
              
              // Calculate average volume
              let sum = 0
              for (let i = 0; i < ttsDataArray.length; i++) {
                sum += ttsDataArray[i]
              }
              const average = sum / ttsDataArray.length
              const ttsVolume = Math.min(average / 128, 1)
              
              console.log(`TTS Volume: ${ttsVolume.toFixed(3)}`)
              
              // Update circle animation based on TTS volume
              updateCircleTTSAnimation(ttsVolume)
              
              if (!currentAudio.paused) {
                ttsVolumeId = requestAnimationFrame(monitorTTSVolume)
              }
            }
            
            // Start monitoring when audio starts playing
            currentAudio.addEventListener('play', () => {
              console.log('TTS audio started, beginning volume monitoring...')
              monitorTTSVolume()
            })
            
            // Stop monitoring when audio ends
            currentAudio.addEventListener('ended', () => {
              console.log('TTS audio ended, stopping volume monitoring...')
              if (ttsVolumeId) {
                cancelAnimationFrame(ttsVolumeId)
                ttsVolumeId = null
              }
              updateCircleTTSAnimation(0)
            })
            
          } catch (error) {
            console.warn('TTS volume monitoring setup failed:', error)
            // Fallback: simulate TTS volume based on audio element volume
            setupFallbackTTSVolumeMonitoring()
          }
        } else {
          console.warn('Audio context not available, using fallback TTS volume monitoring')
          setupFallbackTTSVolumeMonitoring()
        }
        
        currentAudio.onended = () => {
          URL.revokeObjectURL(preparedAudioUrl)
          preparedAudioUrl = null
          console.log('TTS audio playback completed')
        }
        
        currentAudio.onerror = (error) => {
          console.error('Audio playback error:', error)
          URL.revokeObjectURL(preparedAudioUrl)
          preparedAudioUrl = null
        }

        await currentAudio.play()
        console.log('TTS audio playing automatically...')
      }

      // Legacy function for backward compatibility
      async function playTTS() {
        await prepareTTSAudio()
        await playPreparedAudio()
      }

      function stopTTS() {
        if (currentAudio) {
          currentAudio.pause()
          currentAudio = null
        }
        // Clean up prepared audio URL
        if (preparedAudioUrl) {
          URL.revokeObjectURL(preparedAudioUrl)
          preparedAudioUrl = null
        }
      }

      // Initialize the app when DOM is loaded
      document.addEventListener('DOMContentLoaded', function () {
        console.log('Iris Voice Assistant loaded')
        console.log('Test markdown rendering with: testMarkdownRendering()')
        setState('idle')

        // Handle Spotify authentication callback
        handleSpotifyCallback()

        // Set up button hover feedback
        setupButtonHoverFeedback()

        // Check authentication status on page load
        checkAuthenticationStatus()

        // Initialize speech recognition
        if (!initializeSpeechRecognition()) {
          console.warn('Speech recognition not available')
          const instructionText = document.getElementById('instructionText')
          instructionText.textContent =
            'Speech recognition not supported in this browser'
        }
      })

      //   // API functions (keeping for backend integration)
      //   async function testAPI() {
      //     try {
      //       const response = await fetch('/api/health')
      //       const data = await response.json()
      //       console.log('API Health Check:', data)
      //     } catch (error) {
      //       console.error('API Error:', error.message)
      //     }
      //   }

      //   async function simulateVoiceCommand() {
      //     const testCommand = 'Schedule a meeting for tomorrow at 2 PM'
      //     try {
      //       const response = await fetch('/api/process_voice', {
      //         method: 'POST',
      //         headers: {
      //           'Content-Type': 'application/json',
      //         },
      //         body: JSON.stringify({ command: testCommand }),
      //       })
      //       const data = await response.json()
      //       console.log('Voice Command Response:', data)

      //       // Stop listening after processing
      //       setTimeout(() => {
      //         const siriCircle = document.getElementById('siriCircle')
      //         siriCircle.classList.remove('listening')
      //         isListening = false
      //       }, 2000)
      //     } catch (error) {
      //       console.error('Voice Command Error:', error.message)
      //     }
      //   }
    </script>
  </body>
</html>
